{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'tensorflow.python.keras.layers.preprocessing'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import spacy\n",
    "import sklearn\n",
    "from collections import defaultdict, Counter\n",
    "from bisect import bisect_left\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import io\n",
    "import base64\n",
    "import pymp\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from IPython.display import display_html\n",
    "from itertools import chain, cycle\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('..')\n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "from src.eval import *\n",
    "from src.util import *\n",
    "from src import config\n",
    "from src.visualize import *\n",
    "from src.rewards import *\n",
    "pd.set_option('display.float_format', lambda x: '%.02f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/chasembowers/sequence-postprocessing-v2-67-lb/notebook#Sequence-Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../input/feedback-prize-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(f'{root}/train_en.fea')\n",
    "df_gt = pd.read_csv('../working/offline/60/valid_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nothing': 132,\n",
       " 'Claim': 55,\n",
       " 'Evidence': 299,\n",
       " 'Position': 59,\n",
       " 'Concluding Statement': 191,\n",
       " 'Lead': 197,\n",
       " 'Counterclaim': 95,\n",
       " 'Rebuttal': 116}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = {}\n",
    "df['len'] = df.end - df.start\n",
    "max_lens = df.groupby('para_type')['len'].quantile(.995)\n",
    "for i in range(len(ALL_CLASSES)):\n",
    "  MAX_SEQ_LEN[id2dis[i]] = int(max_lens[i])\n",
    "MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_feather(f'{root}/para_label.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32cf15c619a4183a8cd69e55b7fb12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gts = {}\n",
    "for row in tqdm(d.itertuples(), total=len(d)):\n",
    "  gts[row.id] = decode_label_all(row.start, row.para_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890064676bd9453fbe2e5ad9013c1682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = {}\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "  folds[row.id] = row.kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef82ae7b12aa44f2aa7b6310285f438e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subfolds = {}\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "  subfolds[row.id] = np.random.randint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| ensemble_conf.py:136 in <module>\n",
      "    mns: ['deberta-v3.start.nwemb-0.mark_end-0',\n",
      "          'deberta-xlarge.start',\n",
      "          'deberta-v3.start.len1024.stride-256.seq_encoder-0',\n",
      "          'deberta-v3.start.len1024.rnn_layers-2',\n",
      "          'deberta-v3.start.len1280.rnn_type-GRU',\n",
      "          'deberta-v3.end.len1024',\n",
      "          'deberta-v3.start.len1024.rnn_type-GRU',\n",
      "          'deberta-v3.end.len1024.rnn_type-GRU',\n",
      "          'deberta-v3.start.len1280.rnn_layers-2',\n",
      "          'funnel.end.len1024',\n",
      "          'deberta-v3.end.len1024.seq_encoder-0',\n",
      "          'deberta-v3.start.weight_decay',\n",
      "          'deberta.end',\n",
      "          'deberta-v3.end.len1536.seq_encoder-0',\n",
      "          'funnel.start.len1024',\n",
      "          'bart.end.run2',\n",
      "          'deberta-v3.end',\n",
      "          'roberta.start',\n",
      "          'deberta-v3.start.len1600.rnn_layers-2',\n",
      "          'longformer.start.len1600',\n",
      "          'deberta-v3.se',\n",
      "          'deberta-v3.start.nwemb-0',\n",
      "          'bart.se2',\n",
      "          'longformer.start.len1536',\n",
      "          'bart.start.weight_decay',\n",
      "          'deberta-v3.se2.len1024',\n",
      "          'bart.start.len768',\n",
      "          'deberta-xlarge.end',\n",
      "          'longformer.end.len1280',\n",
      "          'deberta-v3.start.len1536',\n",
      "          'bart.start',\n",
      "          'deberta.start.stride-256',\n",
      "          'funnel-xlarge.start.len1024.half_lr.rnn_layers-2',\n",
      "          'deberta-v3.start.len1024.stride-256',\n",
      "          'deberta-v3.start.len1600',\n",
      "          'deberta-v3.start.rnn_layers-2',\n",
      "          'deberta-v3.start.len1024.rnn_bi',\n",
      "          'deberta-v3.start.len1600.rnn_type-GRU',\n",
      "          'bird.start.len1024',\n",
      "          'funnel.start.len1536.bs-8',\n",
      "          'electra.start.nwemb-0',\n",
      "          'deberta-v3-nli.start.len1024',\n",
      "          'deberta.start.mui-end-mid',\n",
      "          'deberta-v3.start.len1024.ucm',\n",
      "          'deberta-xlarge.start.stride-256',\n",
      "          'deberta-v3.start',\n",
      "          'deberta-v3.end.rnn_layers-2',\n",
      "          'deberta-v3.mid',\n",
      "          'longformer.start.len1280',\n",
      "          'tiny.start.len1536',\n",
      "          'deberta-v3.se2',\n",
      "          'tiny.start.len1024',\n",
      "          'albert.start.nwemb-0',\n",
      "          'deberta-v3.end.len1280',\n",
      "          'deberta-v3.start.stride-256.seq_encoder-0',\n",
      "          'deberta-v3.start.len1536.weight_decay',\n",
      "          'bart.end',\n",
      "          'deberta.se',\n",
      "          'deberta-v3.se.len1024',\n",
      "          'deberta-v3.start.len1536.rnn_type-GRU',\n",
      "          'deberta-v3.se.rnn_layers-2',\n",
      "          'deberta.start',\n",
      "          'funnel.start.len1536.rnn_layers-2.bs-8',\n",
      "          'deberta.mid',\n",
      "          'deberta-v3.end.len1536',\n",
      "          'deberta-v3.start.len1024.stride-512.seq_encoder-0',\n",
      "          'xlnet.start',\n",
      "          'deberta-v3.end.len1280.rnn_type-GRU',\n",
      "          'deberta-v3.start.len1280',\n",
      "          'deberta-v3.end.len1536.rnn_layers-2',\n",
      "          'deberta-v3.start.stride-256',\n",
      "          'roberta.start.nwemb-0',\n",
      "          'deberta-v3.start.len1536.rnn_layers-2',\n",
      "          'deberta-v3.start.mark_end-0',\n",
      "          'bart.start.run2',\n",
      "          'deberta-v3.start.len1024.stride-512',\n",
      "          'deberta-v3.start.mui-end-mid',\n",
      "          'deberta-v3.mid.len1024',\n",
      "          'deberta-v3.start.len1024']\n",
      "ic| ensemble_conf.py:273 in <module>\n",
      "    list(zip(mns, weights)): [('deberta-v3.start.nwemb-0.mark_end-0', 8),\n",
      "                              ('deberta-xlarge.start', 6),\n",
      "                              ('deberta-v3.start.len1024.stride-256.seq_encoder-0', 10),\n",
      "                              ('deberta-v3.end.len1024.seq_encoder-0', 6),\n",
      "                              ('deberta-v3.se', 6),\n",
      "                              ('longformer.start.len1536', 9),\n",
      "                              ('deberta-xlarge.end', 0),\n",
      "                              ('deberta-v3.start.len1536', 4),\n",
      "                              ('deberta-v3.start.len1024.stride-256', 6),\n",
      "                              ('deberta-v3.start.len1024.rnn_bi', 5),\n",
      "                              ('deberta-v3.se2', 1),\n",
      "                              ('deberta-v3.start.stride-256.seq_encoder-0', 9),\n",
      "                              ('deberta.start', 6),\n",
      "                              ('roberta.start.nwemb-0', 6),\n",
      "                              ('bart.start.run2', 6),\n",
      "                              ('deberta-v3.mid.len1024', 4)]\n",
      "    len(mns): 16\n",
      "ic| 461123328.py:2 in <module>\n",
      "    v: 60\n",
      "    mns: ['deberta-v3.start.nwemb-0.mark_end-0',\n",
      "          'deberta-xlarge.start',\n",
      "          'deberta-v3.start.len1024.stride-256.seq_encoder-0',\n",
      "          'deberta-v3.end.len1024.seq_encoder-0',\n",
      "          'deberta-v3.se',\n",
      "          'longformer.start.len1536',\n",
      "          'deberta-xlarge.end',\n",
      "          'deberta-v3.start.len1536',\n",
      "          'deberta-v3.start.len1024.stride-256',\n",
      "          'deberta-v3.start.len1024.rnn_bi',\n",
      "          'deberta-v3.se2',\n",
      "          'deberta-v3.start.stride-256.seq_encoder-0',\n",
      "          'deberta.start',\n",
      "          'roberta.start.nwemb-0',\n",
      "          'bart.start.run2',\n",
      "          'deberta-v3.mid.len1024']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60,\n",
       " ['deberta-v3.start.nwemb-0.mark_end-0',\n",
       "  'deberta-xlarge.start',\n",
       "  'deberta-v3.start.len1024.stride-256.seq_encoder-0',\n",
       "  'deberta-v3.end.len1024.seq_encoder-0',\n",
       "  'deberta-v3.se',\n",
       "  'longformer.start.len1536',\n",
       "  'deberta-xlarge.end',\n",
       "  'deberta-v3.start.len1536',\n",
       "  'deberta-v3.start.len1024.stride-256',\n",
       "  'deberta-v3.start.len1024.rnn_bi',\n",
       "  'deberta-v3.se2',\n",
       "  'deberta-v3.start.stride-256.seq_encoder-0',\n",
       "  'deberta.start',\n",
       "  'roberta.start.nwemb-0',\n",
       "  'bart.start.run2',\n",
       "  'deberta-v3.mid.len1024'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ensemble_conf import v, mns\n",
    "ic(v, mns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = gezi.load(f'../working/offline/{v}/valid.pkl')\n",
    "info = gezi.batch2list(info)\n",
    "info = gezi.sort_list_byid(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = gezi.read_pickle(f'../working/offline/{v}/votes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(df.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a751f3d2151f4b74ab0ba710bfdc439e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_dict, se_dict, sec_dict = {}, {}, {}\n",
    "for id in tqdm(ids):\n",
    "  start_dict[id] = {}\n",
    "  se_dict[id] = defaultdict(set)\n",
    "  sec_dict[id] = defaultdict(set)\n",
    "  for i, vote in enumerate(votes):\n",
    "    for item in vote[id]:\n",
    "      start, end = item['start'], item['end']\n",
    "      cls_ = item['cls']\n",
    "      start_dict[id][start] = 1\n",
    "      se_dict[id][(start, end)].add(cls_)\n",
    "      sec_dict[id][(start, end, cls_)].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_dataset(fold=None, subfold=None, infer=False):\n",
    "  total = len(info)\n",
    "  fes = []\n",
    "  scores = []\n",
    "  matches = []\n",
    "  for i in tqdm(range(total)):\n",
    "    # if i > 1:\n",
    "    #   break\n",
    "    x = info[i]\n",
    "    id = x['id']\n",
    "    gt = gts[id]\n",
    "    fe = {}\n",
    "    fe['id'] = id\n",
    "    fe['index'] = i\n",
    "    fe['fold'] = folds[id]\n",
    "    if fold is not None and fe['fold'] != fold:\n",
    "      continue\n",
    "    fe['subfold'] = subfolds[id]\n",
    "    if subfold is not None and fe['subfold'] != subfold:\n",
    "      continue\n",
    "    fe['num_words'] = x['num_words']\n",
    "    fe['seps'] = (x['start_probs'][:,1] > 0.5).sum()\n",
    "    fe['sep_ratio'] = fe['seps'] / fe['num_words']\n",
    "    num_words = x['num_words']\n",
    "    # ic(num_words, start_dict[id], se_dict[id])\n",
    "    for j in range(num_words):\n",
    "      if j not in start_dict[id]:\n",
    "        continue\n",
    "      fe['start'] = j\n",
    "      fe['start_ratio'] = (j + 1) / num_words\n",
    "      fe['start_probs'] = x['probs'][j]\n",
    "      fe['start_sep_prob'] = x['start_probs'][j][1] if j > 0 else 1.\n",
    "      preds = {k: 0 for k in range(NUM_CLASSES)}\n",
    "      fe['start_cls'] = x['preds'][j]\n",
    "      probs = x['probs'][j]\n",
    "      fe['start_cls_prob'] = probs[fe['start_cls']]\n",
    "      fe['max_start_prob'] = probs.max()\n",
    "      preds[x['preds'][j]] += 1\n",
    "      fe['pre_cls'] = -1 if j == 0 else x['preds'][j - 1]\n",
    "      fe['start_diff'] = int(fe['pre_cls'] != fe['start_cls'])\n",
    "      fe['pre_max_prob'] = 1 if j == 0 else x['probs'][j - 1].max()\n",
    "      fe['pre_cls_prob'] = 1 if j == 0 else x['probs'][j - 1][fe['pre_cls']]\n",
    "      sep_count = 0\n",
    "      for k in range(j + 1, num_words):\n",
    "        if (j, k + 1) not in se_dict[id]:\n",
    "          continue\n",
    "        probs = x['probs'][j: k + 1].sum(0)\n",
    "        fe['para_len'] = k + 1 - j\n",
    "        fe['para_len_ratio'] = (k + 1 - j) / num_words\n",
    "        preds[x['preds'][k]] += 1  \n",
    "        fe['end'] = k + 1\n",
    "        fe['end_ratio'] = (k + 1) / num_words\n",
    "        fe['end_probs'] = x['probs'][k]\n",
    "        fe['max_end_prob'] = x['probs'][k + 1].max() if k + 1 < num_words else 1\n",
    "        end_cls = np.argmax(x['probs'][k])\n",
    "        fe['end_cls'] = end_cls\n",
    "        fe['end_cls_prob'] = x['probs'][k][end_cls]\n",
    "        fe['end_sep_prob'] = x['start_probs'][k + 1][1] if k + 1 < num_words else 1.\n",
    "        fe['sep_add_prob'] = (fe['start_sep_prob'] + fe['end_sep_prob']) / 2.\n",
    "        fe['sep_mul_prob'] = (fe['start_sep_prob'] * fe['end_sep_prob']) ** 0.5\n",
    "        fe['num_classes'] = len([k for k in range(NUM_CLASSES) if preds[k] > 0])\n",
    "        mean_probs = gezi.softmax(probs)\n",
    "        fe['mean_probs'] = mean_probs\n",
    "        fe['max_prob'] = mean_probs.max()\n",
    "        top_classes = np.argsort(-mean_probs,axis=0)[:2]\n",
    "        fe['top_class'] = top_classes[0]\n",
    "        fe['top_class2'] = top_classes[1]\n",
    "        fe['next_cls'] = -1 if k + 1  == num_words else x['preds'][k + 1]\n",
    "        fe['end_diff'] = int(fe['next_cls'] != fe['end_cls'])\n",
    "        fe['next_max_prob'] = 1 if k + 1  == num_words else x['probs'][k + 1].max()\n",
    "        # top_classes = top_classes[:1]\n",
    "\n",
    "        for cls in range(len(ALL_CLASSES)):\n",
    "          # if cls not in se_dict[id][(j, k + 1)]:\n",
    "          #   continue\n",
    "          if fe['mean_probs'].argmax() != cls:\n",
    "            continue\n",
    "          for idx in range(len(votes)):\n",
    "            fe[f'model{idx}'] = 0\n",
    "          model_matches = 0\n",
    "          for idx in sec_dict[id][(j, k + 1, cls)]:\n",
    "            fe[f'model{idx}'] = 1\n",
    "            model_matches += 1\n",
    "          fe['model_matches'] = model_matches / len(votes)\n",
    "          fe['mean_prob'] = fe['mean_probs'][cls]\n",
    "          if fe['mean_prob'] < proba_thresh[id2dis[cls]]:\n",
    "            continue\n",
    "          fe['start_prob'] = x['probs'][j][cls]\n",
    "          fe['end_prob'] = x['probs'][k][cls]\n",
    "          fe['class_ratio'] = (x['preds'][j:k+1] == cls).sum() / fe['para_len']\n",
    "          # fe['class_max_prob'] = x['probs'][j:k+1][cls].max()\n",
    "          # fe['class_min_prob'] = x['probs'][j:k+1][cls].min()\n",
    "          fe['start_eq'] = int(fe['start_cls'] == fe['pre_cls'])\n",
    "          fe['start_eq2'] = int(cls == fe['pre_cls'])\n",
    "          fe['end_eq'] = int(fe['end_cls'] == fe['next_cls'])\n",
    "          fe['end_eq2'] = int(cls == fe['next_cls'])\n",
    "          fe['cls'] = cls\n",
    "          fe['is_top_class'] = int(cls == fe['top_class'])\n",
    "          fe['is_top_class2'] = int(cls == fe['top_class2'])\n",
    "          if not infer:\n",
    "            fe['score'] = best_match(gt[cls], [j, k + 1])\n",
    "            fe['match'] = calc_match(gt[cls], [[j, k + 1]])\n",
    "\n",
    "            scores.append(fe['score'])\n",
    "            matches.append(fe['match'])\n",
    "          fes.append(fe.copy())\n",
    "\n",
    "  # if not infer:\n",
    "  #   ic(len(scores), len(matches))\n",
    "  #   ic(np.mean(scores), np.mean(matches))\n",
    "  d = pd.DataFrame(fes)\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa502a0bb6374aa383b91eed4cf450d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dall = para_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>fold</th>\n",
       "      <th>subfold</th>\n",
       "      <th>num_words</th>\n",
       "      <th>seps</th>\n",
       "      <th>sep_ratio</th>\n",
       "      <th>start</th>\n",
       "      <th>start_ratio</th>\n",
       "      <th>start_probs</th>\n",
       "      <th>...</th>\n",
       "      <th>class_ratio</th>\n",
       "      <th>start_eq</th>\n",
       "      <th>start_eq2</th>\n",
       "      <th>end_eq</th>\n",
       "      <th>end_eq2</th>\n",
       "      <th>cls</th>\n",
       "      <th>is_top_class</th>\n",
       "      <th>is_top_class2</th>\n",
       "      <th>score</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.001917590759271003, 0.0019244975630331909, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.001917590759271003, 0.0019244975630331909, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[0.007096823139469225, 0.0038828863716732975, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0030103651257567298, 0.04211587626663227, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0030103651257567298, 0.04211587626663227, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492043</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>15593</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.00846240406675545, 0.1874541361694501, 0.75...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492044</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>15593</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>[0.004458047269476028, 0.20680522259614403, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492045</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>15593</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>[0.013228141344881891, 0.07948528910714266, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492046</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>15593</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>[0.013228141344881891, 0.07948528910714266, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492047</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>15593</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>98</td>\n",
       "      <td>0.59</td>\n",
       "      <td>[0.010516902945622606, 0.1296692431464633, 0.8...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492048 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  index  fold  subfold  num_words  seps  sep_ratio  start  \\\n",
       "0       0000D23A521A      0     0        0        251     9       0.04      0   \n",
       "1       0000D23A521A      0     0        0        251     9       0.04      0   \n",
       "2       0000D23A521A      0     0        0        251     9       0.04     16   \n",
       "3       0000D23A521A      0     0        0        251     9       0.04     21   \n",
       "4       0000D23A521A      0     0        0        251     9       0.04     21   \n",
       "...              ...    ...   ...      ...        ...   ...        ...    ...   \n",
       "492043  FFFF80B8CC2F  15593     3        3        168     2       0.01     60   \n",
       "492044  FFFF80B8CC2F  15593     3        3        168     2       0.01     63   \n",
       "492045  FFFF80B8CC2F  15593     3        3        168     2       0.01     80   \n",
       "492046  FFFF80B8CC2F  15593     3        3        168     2       0.01     80   \n",
       "492047  FFFF80B8CC2F  15593     3        3        168     2       0.01     98   \n",
       "\n",
       "        start_ratio                                        start_probs  ...  \\\n",
       "0              0.00  [0.001917590759271003, 0.0019244975630331909, ...  ...   \n",
       "1              0.00  [0.001917590759271003, 0.0019244975630331909, ...  ...   \n",
       "2              0.07  [0.007096823139469225, 0.0038828863716732975, ...  ...   \n",
       "3              0.09  [0.0030103651257567298, 0.04211587626663227, 0...  ...   \n",
       "4              0.09  [0.0030103651257567298, 0.04211587626663227, 0...  ...   \n",
       "...             ...                                                ...  ...   \n",
       "492043         0.36  [0.00846240406675545, 0.1874541361694501, 0.75...  ...   \n",
       "492044         0.38  [0.004458047269476028, 0.20680522259614403, 0....  ...   \n",
       "492045         0.48  [0.013228141344881891, 0.07948528910714266, 0....  ...   \n",
       "492046         0.48  [0.013228141344881891, 0.07948528910714266, 0....  ...   \n",
       "492047         0.59  [0.010516902945622606, 0.1296692431464633, 0.8...  ...   \n",
       "\n",
       "        class_ratio  start_eq  start_eq2  end_eq  end_eq2  cls  is_top_class  \\\n",
       "0              1.00         0          0       1        1    5             1   \n",
       "1              1.00         0          0       0        0    5             1   \n",
       "2              0.72         1          0       0        0    3             1   \n",
       "3              1.00         0          0       0        0    3             1   \n",
       "4              0.68         0          0       1        0    3             1   \n",
       "...             ...       ...        ...     ...      ...  ...           ...   \n",
       "492043         1.00         1          1       1        1    2             1   \n",
       "492044         1.00         1          1       1        1    2             1   \n",
       "492045         1.00         1          1       1        1    2             1   \n",
       "492046         1.00         1          1       0        0    2             1   \n",
       "492047         1.00         1          1       0        0    2             1   \n",
       "\n",
       "        is_top_class2  score  match  \n",
       "0                   0   0.00      0  \n",
       "1                   0   0.00      0  \n",
       "2                   0   0.53      1  \n",
       "3                   0   0.38      0  \n",
       "4                   0   0.33      0  \n",
       "...               ...    ...    ...  \n",
       "492043              0   0.12      0  \n",
       "492044              0   0.10      0  \n",
       "492045              0   0.11      0  \n",
       "492046              0   0.46      0  \n",
       "492047              0   0.35      0  \n",
       "\n",
       "[492048 rows x 68 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = dall[dall.fold==0]\n",
    "dtrain = dall[dall.fold!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = d[d.subfold != 0]\n",
    "# # dtrain = d0[d0.subfold == 1]\n",
    "# dvalid = d[d.subfold == 0]\n",
    "reg_cols =  [\n",
    "              'num_words', \n",
    "              'start', \n",
    "              'start_ratio', \n",
    "              'end', \n",
    "              'end_ratio',\n",
    "              'start_sep_prob', \n",
    "              'end_sep_prob', \n",
    "              'para_len', \n",
    "              'para_len_ratio',\n",
    "              'num_classes', \n",
    "              'mean_prob', \n",
    "              'start_prob', \n",
    "              'end_prob', \n",
    "              'start_eq',\n",
    "              'start_eq2',\n",
    "              'end_eq',\n",
    "              'end_eq2',\n",
    "              # 'seps', 'sep_ratio', \n",
    "              'class_ratio',\n",
    "              'max_prob',\n",
    "              'model_matches',\n",
    "              # 'sep_add_prob', \n",
    "              # 'sep_mul_prob', \n",
    "              # 'is_top_class', \n",
    "              # 'is_top_class2',\n",
    "              # 'class_max_prob', 'class_min_prob'\n",
    "              # 'start_cls_prob',\n",
    "              # 'pre_cls_prob',\n",
    "              # 'end_cls_prob',\n",
    "              # 'start_diff',\n",
    "              # 'end_diff',\n",
    "        ]\n",
    "for idx in range(len(votes)):\n",
    "  reg_cols += [f'model{idx}']\n",
    "cat_cols = [\n",
    "            'cls', \n",
    "            'start_cls', \n",
    "            'end_cls',\n",
    "            # 'top_class',\n",
    "            'pre_cls', \n",
    "            'next_cls'\n",
    "            ]\n",
    "# label_col = 'match'\n",
    "label_col = 'score'\n",
    "cols = reg_cols + cat_cols\n",
    "X_train = dtrain[cols]\n",
    "y_train = dtrain[[label_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = dvalid[cols]\n",
    "# y_valid = dvalid[[label_col]]\n",
    "y_valid = dvalid[['match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_boost_round = 2000\n",
    "params = {\n",
    "          # \"objective\": \"binary\",\n",
    "          \"objective\": \"regression\" if label_col is 'score' else 'binary',\n",
    "          # \"objective\": \"cross_entropy\",\n",
    "          \"metric\": \"auc\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": 6,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.9,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": True,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 200,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"bagging_freq\": 5,\n",
    "          \"bagging_fraction\": 0.9,\n",
    "          # \"num_trees\": 200,\n",
    "          \"subsample\": 0.9\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[1]\tvalid_0's auc: 0.715275\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.724499\n",
      "[3]\tvalid_0's auc: 0.735714\n",
      "[4]\tvalid_0's auc: 0.741155\n",
      "[5]\tvalid_0's auc: 0.742532\n",
      "[6]\tvalid_0's auc: 0.748307\n",
      "[7]\tvalid_0's auc: 0.758245\n",
      "[8]\tvalid_0's auc: 0.762038\n",
      "[9]\tvalid_0's auc: 0.76265\n",
      "[10]\tvalid_0's auc: 0.763973\n",
      "[11]\tvalid_0's auc: 0.767598\n",
      "[12]\tvalid_0's auc: 0.770335\n",
      "[13]\tvalid_0's auc: 0.770737\n",
      "[14]\tvalid_0's auc: 0.772135\n",
      "[15]\tvalid_0's auc: 0.772819\n",
      "[16]\tvalid_0's auc: 0.774734\n",
      "[17]\tvalid_0's auc: 0.77512\n",
      "[18]\tvalid_0's auc: 0.775672\n",
      "[19]\tvalid_0's auc: 0.776605\n",
      "[20]\tvalid_0's auc: 0.777929\n",
      "[21]\tvalid_0's auc: 0.778377\n",
      "[22]\tvalid_0's auc: 0.779413\n",
      "[23]\tvalid_0's auc: 0.780519\n",
      "[24]\tvalid_0's auc: 0.781971\n",
      "[25]\tvalid_0's auc: 0.782725\n",
      "[26]\tvalid_0's auc: 0.783046\n",
      "[27]\tvalid_0's auc: 0.783436\n",
      "[28]\tvalid_0's auc: 0.784558\n",
      "[29]\tvalid_0's auc: 0.785602\n",
      "[30]\tvalid_0's auc: 0.786131\n",
      "[31]\tvalid_0's auc: 0.787301\n",
      "[32]\tvalid_0's auc: 0.787507\n",
      "[33]\tvalid_0's auc: 0.78819\n",
      "[34]\tvalid_0's auc: 0.788784\n",
      "[35]\tvalid_0's auc: 0.789371\n",
      "[36]\tvalid_0's auc: 0.789964\n",
      "[37]\tvalid_0's auc: 0.790502\n",
      "[38]\tvalid_0's auc: 0.790685\n",
      "[39]\tvalid_0's auc: 0.790964\n",
      "[40]\tvalid_0's auc: 0.791191\n",
      "[41]\tvalid_0's auc: 0.791816\n",
      "[42]\tvalid_0's auc: 0.792589\n",
      "[43]\tvalid_0's auc: 0.792884\n",
      "[44]\tvalid_0's auc: 0.79328\n",
      "[45]\tvalid_0's auc: 0.793611\n",
      "[46]\tvalid_0's auc: 0.793895\n",
      "[47]\tvalid_0's auc: 0.793885\n",
      "[48]\tvalid_0's auc: 0.794173\n",
      "[49]\tvalid_0's auc: 0.794643\n",
      "[50]\tvalid_0's auc: 0.794875\n",
      "[51]\tvalid_0's auc: 0.795311\n",
      "[52]\tvalid_0's auc: 0.795643\n",
      "[53]\tvalid_0's auc: 0.795842\n",
      "[54]\tvalid_0's auc: 0.795938\n",
      "[55]\tvalid_0's auc: 0.796344\n",
      "[56]\tvalid_0's auc: 0.796566\n",
      "[57]\tvalid_0's auc: 0.796848\n",
      "[58]\tvalid_0's auc: 0.796944\n",
      "[59]\tvalid_0's auc: 0.79732\n",
      "[60]\tvalid_0's auc: 0.797604\n",
      "[61]\tvalid_0's auc: 0.797789\n",
      "[62]\tvalid_0's auc: 0.798024\n",
      "[63]\tvalid_0's auc: 0.798323\n",
      "[64]\tvalid_0's auc: 0.798341\n",
      "[65]\tvalid_0's auc: 0.798551\n",
      "[66]\tvalid_0's auc: 0.798812\n",
      "[67]\tvalid_0's auc: 0.798972\n",
      "[68]\tvalid_0's auc: 0.799126\n",
      "[69]\tvalid_0's auc: 0.799456\n",
      "[70]\tvalid_0's auc: 0.799602\n",
      "[71]\tvalid_0's auc: 0.799646\n",
      "[72]\tvalid_0's auc: 0.799687\n",
      "[73]\tvalid_0's auc: 0.79983\n",
      "[74]\tvalid_0's auc: 0.800039\n",
      "[75]\tvalid_0's auc: 0.800235\n",
      "[76]\tvalid_0's auc: 0.800486\n",
      "[77]\tvalid_0's auc: 0.800582\n",
      "[78]\tvalid_0's auc: 0.800648\n",
      "[79]\tvalid_0's auc: 0.800764\n",
      "[80]\tvalid_0's auc: 0.800896\n",
      "[81]\tvalid_0's auc: 0.801135\n",
      "[82]\tvalid_0's auc: 0.801237\n",
      "[83]\tvalid_0's auc: 0.801436\n",
      "[84]\tvalid_0's auc: 0.801617\n",
      "[85]\tvalid_0's auc: 0.801714\n",
      "[86]\tvalid_0's auc: 0.801853\n",
      "[87]\tvalid_0's auc: 0.802014\n",
      "[88]\tvalid_0's auc: 0.802145\n",
      "[89]\tvalid_0's auc: 0.802261\n",
      "[90]\tvalid_0's auc: 0.802417\n",
      "[91]\tvalid_0's auc: 0.8025\n",
      "[92]\tvalid_0's auc: 0.802544\n",
      "[93]\tvalid_0's auc: 0.802597\n",
      "[94]\tvalid_0's auc: 0.802691\n",
      "[95]\tvalid_0's auc: 0.8027\n",
      "[96]\tvalid_0's auc: 0.802823\n",
      "[97]\tvalid_0's auc: 0.802892\n",
      "[98]\tvalid_0's auc: 0.802996\n",
      "[99]\tvalid_0's auc: 0.803041\n",
      "[100]\tvalid_0's auc: 0.803178\n",
      "[101]\tvalid_0's auc: 0.803259\n",
      "[102]\tvalid_0's auc: 0.803318\n",
      "[103]\tvalid_0's auc: 0.803363\n",
      "[104]\tvalid_0's auc: 0.803462\n",
      "[105]\tvalid_0's auc: 0.803502\n",
      "[106]\tvalid_0's auc: 0.803561\n",
      "[107]\tvalid_0's auc: 0.803699\n",
      "[108]\tvalid_0's auc: 0.803736\n",
      "[109]\tvalid_0's auc: 0.803752\n",
      "[110]\tvalid_0's auc: 0.803807\n",
      "[111]\tvalid_0's auc: 0.80395\n",
      "[112]\tvalid_0's auc: 0.804012\n",
      "[113]\tvalid_0's auc: 0.804087\n",
      "[114]\tvalid_0's auc: 0.80413\n",
      "[115]\tvalid_0's auc: 0.804242\n",
      "[116]\tvalid_0's auc: 0.804346\n",
      "[117]\tvalid_0's auc: 0.804434\n",
      "[118]\tvalid_0's auc: 0.804514\n",
      "[119]\tvalid_0's auc: 0.804598\n",
      "[120]\tvalid_0's auc: 0.804737\n",
      "[121]\tvalid_0's auc: 0.804768\n",
      "[122]\tvalid_0's auc: 0.804817\n",
      "[123]\tvalid_0's auc: 0.80491\n",
      "[124]\tvalid_0's auc: 0.804938\n",
      "[125]\tvalid_0's auc: 0.805055\n",
      "[126]\tvalid_0's auc: 0.805133\n",
      "[127]\tvalid_0's auc: 0.805186\n",
      "[128]\tvalid_0's auc: 0.805247\n",
      "[129]\tvalid_0's auc: 0.805299\n",
      "[130]\tvalid_0's auc: 0.80537\n",
      "[131]\tvalid_0's auc: 0.805459\n",
      "[132]\tvalid_0's auc: 0.805497\n",
      "[133]\tvalid_0's auc: 0.805611\n",
      "[134]\tvalid_0's auc: 0.805667\n",
      "[135]\tvalid_0's auc: 0.805694\n",
      "[136]\tvalid_0's auc: 0.80573\n",
      "[137]\tvalid_0's auc: 0.805798\n",
      "[138]\tvalid_0's auc: 0.805852\n",
      "[139]\tvalid_0's auc: 0.805919\n",
      "[140]\tvalid_0's auc: 0.805939\n",
      "[141]\tvalid_0's auc: 0.805987\n",
      "[142]\tvalid_0's auc: 0.806026\n",
      "[143]\tvalid_0's auc: 0.806113\n",
      "[144]\tvalid_0's auc: 0.806121\n",
      "[145]\tvalid_0's auc: 0.806154\n",
      "[146]\tvalid_0's auc: 0.806172\n",
      "[147]\tvalid_0's auc: 0.806207\n",
      "[148]\tvalid_0's auc: 0.80624\n",
      "[149]\tvalid_0's auc: 0.806222\n",
      "[150]\tvalid_0's auc: 0.806242\n",
      "[151]\tvalid_0's auc: 0.806267\n",
      "[152]\tvalid_0's auc: 0.806318\n",
      "[153]\tvalid_0's auc: 0.806348\n",
      "[154]\tvalid_0's auc: 0.806379\n",
      "[155]\tvalid_0's auc: 0.806394\n",
      "[156]\tvalid_0's auc: 0.806409\n",
      "[157]\tvalid_0's auc: 0.806473\n",
      "[158]\tvalid_0's auc: 0.806524\n",
      "[159]\tvalid_0's auc: 0.806594\n",
      "[160]\tvalid_0's auc: 0.806615\n",
      "[161]\tvalid_0's auc: 0.806705\n",
      "[162]\tvalid_0's auc: 0.806813\n",
      "[163]\tvalid_0's auc: 0.806848\n",
      "[164]\tvalid_0's auc: 0.806924\n",
      "[165]\tvalid_0's auc: 0.80701\n",
      "[166]\tvalid_0's auc: 0.807023\n",
      "[167]\tvalid_0's auc: 0.807096\n",
      "[168]\tvalid_0's auc: 0.807121\n",
      "[169]\tvalid_0's auc: 0.807175\n",
      "[170]\tvalid_0's auc: 0.8072\n",
      "[171]\tvalid_0's auc: 0.80723\n",
      "[172]\tvalid_0's auc: 0.807274\n",
      "[173]\tvalid_0's auc: 0.807299\n",
      "[174]\tvalid_0's auc: 0.807362\n",
      "[175]\tvalid_0's auc: 0.807381\n",
      "[176]\tvalid_0's auc: 0.807466\n",
      "[177]\tvalid_0's auc: 0.807507\n",
      "[178]\tvalid_0's auc: 0.80757\n",
      "[179]\tvalid_0's auc: 0.807595\n",
      "[180]\tvalid_0's auc: 0.807629\n",
      "[181]\tvalid_0's auc: 0.807605\n",
      "[182]\tvalid_0's auc: 0.807689\n",
      "[183]\tvalid_0's auc: 0.807704\n",
      "[184]\tvalid_0's auc: 0.807731\n",
      "[185]\tvalid_0's auc: 0.807782\n",
      "[186]\tvalid_0's auc: 0.807807\n",
      "[187]\tvalid_0's auc: 0.807842\n",
      "[188]\tvalid_0's auc: 0.807855\n",
      "[189]\tvalid_0's auc: 0.80785\n",
      "[190]\tvalid_0's auc: 0.807902\n",
      "[191]\tvalid_0's auc: 0.807926\n",
      "[192]\tvalid_0's auc: 0.807926\n",
      "[193]\tvalid_0's auc: 0.807941\n",
      "[194]\tvalid_0's auc: 0.807944\n",
      "[195]\tvalid_0's auc: 0.807953\n",
      "[196]\tvalid_0's auc: 0.808006\n",
      "[197]\tvalid_0's auc: 0.808021\n",
      "[198]\tvalid_0's auc: 0.808057\n",
      "[199]\tvalid_0's auc: 0.808108\n",
      "[200]\tvalid_0's auc: 0.808146\n",
      "[201]\tvalid_0's auc: 0.808168\n",
      "[202]\tvalid_0's auc: 0.808208\n",
      "[203]\tvalid_0's auc: 0.808296\n",
      "[204]\tvalid_0's auc: 0.808298\n",
      "[205]\tvalid_0's auc: 0.808347\n",
      "[206]\tvalid_0's auc: 0.808395\n",
      "[207]\tvalid_0's auc: 0.808432\n",
      "[208]\tvalid_0's auc: 0.80843\n",
      "[209]\tvalid_0's auc: 0.80846\n",
      "[210]\tvalid_0's auc: 0.808482\n",
      "[211]\tvalid_0's auc: 0.808508\n",
      "[212]\tvalid_0's auc: 0.80856\n",
      "[213]\tvalid_0's auc: 0.808593\n",
      "[214]\tvalid_0's auc: 0.808627\n",
      "[215]\tvalid_0's auc: 0.808659\n",
      "[216]\tvalid_0's auc: 0.808673\n",
      "[217]\tvalid_0's auc: 0.808697\n",
      "[218]\tvalid_0's auc: 0.808738\n",
      "[219]\tvalid_0's auc: 0.8088\n",
      "[220]\tvalid_0's auc: 0.808841\n",
      "[221]\tvalid_0's auc: 0.808877\n",
      "[222]\tvalid_0's auc: 0.80888\n",
      "[223]\tvalid_0's auc: 0.808937\n",
      "[224]\tvalid_0's auc: 0.80895\n",
      "[225]\tvalid_0's auc: 0.808987\n",
      "[226]\tvalid_0's auc: 0.808976\n",
      "[227]\tvalid_0's auc: 0.808979\n",
      "[228]\tvalid_0's auc: 0.808994\n",
      "[229]\tvalid_0's auc: 0.80903\n",
      "[230]\tvalid_0's auc: 0.80903\n",
      "[231]\tvalid_0's auc: 0.809059\n",
      "[232]\tvalid_0's auc: 0.809118\n",
      "[233]\tvalid_0's auc: 0.809123\n",
      "[234]\tvalid_0's auc: 0.809168\n",
      "[235]\tvalid_0's auc: 0.809201\n",
      "[236]\tvalid_0's auc: 0.809219\n",
      "[237]\tvalid_0's auc: 0.809273\n",
      "[238]\tvalid_0's auc: 0.809295\n",
      "[239]\tvalid_0's auc: 0.809325\n",
      "[240]\tvalid_0's auc: 0.80934\n",
      "[241]\tvalid_0's auc: 0.809378\n",
      "[242]\tvalid_0's auc: 0.809397\n",
      "[243]\tvalid_0's auc: 0.809394\n",
      "[244]\tvalid_0's auc: 0.809399\n",
      "[245]\tvalid_0's auc: 0.80945\n",
      "[246]\tvalid_0's auc: 0.809465\n",
      "[247]\tvalid_0's auc: 0.809469\n",
      "[248]\tvalid_0's auc: 0.809495\n",
      "[249]\tvalid_0's auc: 0.809508\n",
      "[250]\tvalid_0's auc: 0.809524\n",
      "[251]\tvalid_0's auc: 0.809541\n",
      "[252]\tvalid_0's auc: 0.809614\n",
      "[253]\tvalid_0's auc: 0.809637\n",
      "[254]\tvalid_0's auc: 0.809638\n",
      "[255]\tvalid_0's auc: 0.809638\n",
      "[256]\tvalid_0's auc: 0.809669\n",
      "[257]\tvalid_0's auc: 0.809667\n",
      "[258]\tvalid_0's auc: 0.809669\n",
      "[259]\tvalid_0's auc: 0.809691\n",
      "[260]\tvalid_0's auc: 0.8097\n",
      "[261]\tvalid_0's auc: 0.809738\n",
      "[262]\tvalid_0's auc: 0.809763\n",
      "[263]\tvalid_0's auc: 0.809821\n",
      "[264]\tvalid_0's auc: 0.809862\n",
      "[265]\tvalid_0's auc: 0.809883\n",
      "[266]\tvalid_0's auc: 0.809879\n",
      "[267]\tvalid_0's auc: 0.809889\n",
      "[268]\tvalid_0's auc: 0.809937\n",
      "[269]\tvalid_0's auc: 0.809956\n",
      "[270]\tvalid_0's auc: 0.80998\n",
      "[271]\tvalid_0's auc: 0.809982\n",
      "[272]\tvalid_0's auc: 0.810018\n",
      "[273]\tvalid_0's auc: 0.810025\n",
      "[274]\tvalid_0's auc: 0.810001\n",
      "[275]\tvalid_0's auc: 0.810019\n",
      "[276]\tvalid_0's auc: 0.810034\n",
      "[277]\tvalid_0's auc: 0.810042\n",
      "[278]\tvalid_0's auc: 0.810062\n",
      "[279]\tvalid_0's auc: 0.810065\n",
      "[280]\tvalid_0's auc: 0.810077\n",
      "[281]\tvalid_0's auc: 0.810093\n",
      "[282]\tvalid_0's auc: 0.810134\n",
      "[283]\tvalid_0's auc: 0.810144\n",
      "[284]\tvalid_0's auc: 0.810154\n",
      "[285]\tvalid_0's auc: 0.810161\n",
      "[286]\tvalid_0's auc: 0.810196\n",
      "[287]\tvalid_0's auc: 0.810236\n",
      "[288]\tvalid_0's auc: 0.81029\n",
      "[289]\tvalid_0's auc: 0.810316\n",
      "[290]\tvalid_0's auc: 0.810336\n",
      "[291]\tvalid_0's auc: 0.810354\n",
      "[292]\tvalid_0's auc: 0.810384\n",
      "[293]\tvalid_0's auc: 0.810402\n",
      "[294]\tvalid_0's auc: 0.810439\n",
      "[295]\tvalid_0's auc: 0.810444\n",
      "[296]\tvalid_0's auc: 0.810452\n",
      "[297]\tvalid_0's auc: 0.810472\n",
      "[298]\tvalid_0's auc: 0.810498\n",
      "[299]\tvalid_0's auc: 0.810543\n",
      "[300]\tvalid_0's auc: 0.810567\n",
      "[301]\tvalid_0's auc: 0.810601\n",
      "[302]\tvalid_0's auc: 0.810622\n",
      "[303]\tvalid_0's auc: 0.810635\n",
      "[304]\tvalid_0's auc: 0.810626\n",
      "[305]\tvalid_0's auc: 0.810668\n",
      "[306]\tvalid_0's auc: 0.810672\n",
      "[307]\tvalid_0's auc: 0.810697\n",
      "[308]\tvalid_0's auc: 0.810705\n",
      "[309]\tvalid_0's auc: 0.810761\n",
      "[310]\tvalid_0's auc: 0.810765\n",
      "[311]\tvalid_0's auc: 0.810792\n",
      "[312]\tvalid_0's auc: 0.810804\n",
      "[313]\tvalid_0's auc: 0.810812\n",
      "[314]\tvalid_0's auc: 0.810819\n",
      "[315]\tvalid_0's auc: 0.810817\n",
      "[316]\tvalid_0's auc: 0.810828\n",
      "[317]\tvalid_0's auc: 0.810851\n",
      "[318]\tvalid_0's auc: 0.810859\n",
      "[319]\tvalid_0's auc: 0.810876\n",
      "[320]\tvalid_0's auc: 0.810912\n",
      "[321]\tvalid_0's auc: 0.810904\n",
      "[322]\tvalid_0's auc: 0.810912\n",
      "[323]\tvalid_0's auc: 0.810914\n",
      "[324]\tvalid_0's auc: 0.810946\n",
      "[325]\tvalid_0's auc: 0.810953\n",
      "[326]\tvalid_0's auc: 0.810972\n",
      "[327]\tvalid_0's auc: 0.810985\n",
      "[328]\tvalid_0's auc: 0.811006\n",
      "[329]\tvalid_0's auc: 0.811009\n",
      "[330]\tvalid_0's auc: 0.811022\n",
      "[331]\tvalid_0's auc: 0.811047\n",
      "[332]\tvalid_0's auc: 0.811068\n",
      "[333]\tvalid_0's auc: 0.811065\n",
      "[334]\tvalid_0's auc: 0.811095\n",
      "[335]\tvalid_0's auc: 0.811091\n",
      "[336]\tvalid_0's auc: 0.811102\n",
      "[337]\tvalid_0's auc: 0.811112\n",
      "[338]\tvalid_0's auc: 0.811112\n",
      "[339]\tvalid_0's auc: 0.811107\n",
      "[340]\tvalid_0's auc: 0.811122\n",
      "[341]\tvalid_0's auc: 0.811136\n",
      "[342]\tvalid_0's auc: 0.811122\n",
      "[343]\tvalid_0's auc: 0.811132\n",
      "[344]\tvalid_0's auc: 0.811161\n",
      "[345]\tvalid_0's auc: 0.811145\n",
      "[346]\tvalid_0's auc: 0.811161\n",
      "[347]\tvalid_0's auc: 0.811175\n",
      "[348]\tvalid_0's auc: 0.811203\n",
      "[349]\tvalid_0's auc: 0.811202\n",
      "[350]\tvalid_0's auc: 0.811199\n",
      "[351]\tvalid_0's auc: 0.811198\n",
      "[352]\tvalid_0's auc: 0.811229\n",
      "[353]\tvalid_0's auc: 0.811248\n",
      "[354]\tvalid_0's auc: 0.81124\n",
      "[355]\tvalid_0's auc: 0.811234\n",
      "[356]\tvalid_0's auc: 0.811287\n",
      "[357]\tvalid_0's auc: 0.811305\n",
      "[358]\tvalid_0's auc: 0.811331\n",
      "[359]\tvalid_0's auc: 0.811355\n",
      "[360]\tvalid_0's auc: 0.811396\n",
      "[361]\tvalid_0's auc: 0.81142\n",
      "[362]\tvalid_0's auc: 0.811431\n",
      "[363]\tvalid_0's auc: 0.811424\n",
      "[364]\tvalid_0's auc: 0.811428\n",
      "[365]\tvalid_0's auc: 0.811436\n",
      "[366]\tvalid_0's auc: 0.811433\n",
      "[367]\tvalid_0's auc: 0.811462\n",
      "[368]\tvalid_0's auc: 0.811479\n",
      "[369]\tvalid_0's auc: 0.811498\n",
      "[370]\tvalid_0's auc: 0.811509\n",
      "[371]\tvalid_0's auc: 0.811518\n",
      "[372]\tvalid_0's auc: 0.811515\n",
      "[373]\tvalid_0's auc: 0.811527\n",
      "[374]\tvalid_0's auc: 0.81157\n",
      "[375]\tvalid_0's auc: 0.811597\n",
      "[376]\tvalid_0's auc: 0.811625\n",
      "[377]\tvalid_0's auc: 0.811626\n",
      "[378]\tvalid_0's auc: 0.81165\n",
      "[379]\tvalid_0's auc: 0.811664\n",
      "[380]\tvalid_0's auc: 0.81166\n",
      "[381]\tvalid_0's auc: 0.811677\n",
      "[382]\tvalid_0's auc: 0.811688\n",
      "[383]\tvalid_0's auc: 0.811724\n",
      "[384]\tvalid_0's auc: 0.811796\n",
      "[385]\tvalid_0's auc: 0.81181\n",
      "[386]\tvalid_0's auc: 0.811803\n",
      "[387]\tvalid_0's auc: 0.811823\n",
      "[388]\tvalid_0's auc: 0.811831\n",
      "[389]\tvalid_0's auc: 0.811841\n",
      "[390]\tvalid_0's auc: 0.811844\n",
      "[391]\tvalid_0's auc: 0.811843\n",
      "[392]\tvalid_0's auc: 0.811869\n",
      "[393]\tvalid_0's auc: 0.811882\n",
      "[394]\tvalid_0's auc: 0.811892\n",
      "[395]\tvalid_0's auc: 0.811893\n",
      "[396]\tvalid_0's auc: 0.811895\n",
      "[397]\tvalid_0's auc: 0.811907\n",
      "[398]\tvalid_0's auc: 0.81191\n",
      "[399]\tvalid_0's auc: 0.811961\n",
      "[400]\tvalid_0's auc: 0.811969\n",
      "[401]\tvalid_0's auc: 0.811968\n",
      "[402]\tvalid_0's auc: 0.811971\n",
      "[403]\tvalid_0's auc: 0.811982\n",
      "[404]\tvalid_0's auc: 0.812\n",
      "[405]\tvalid_0's auc: 0.811998\n",
      "[406]\tvalid_0's auc: 0.812024\n",
      "[407]\tvalid_0's auc: 0.812064\n",
      "[408]\tvalid_0's auc: 0.812064\n",
      "[409]\tvalid_0's auc: 0.812084\n",
      "[410]\tvalid_0's auc: 0.812086\n",
      "[411]\tvalid_0's auc: 0.8121\n",
      "[412]\tvalid_0's auc: 0.812111\n",
      "[413]\tvalid_0's auc: 0.812131\n",
      "[414]\tvalid_0's auc: 0.812142\n",
      "[415]\tvalid_0's auc: 0.812155\n",
      "[416]\tvalid_0's auc: 0.812155\n",
      "[417]\tvalid_0's auc: 0.812167\n",
      "[418]\tvalid_0's auc: 0.812164\n",
      "[419]\tvalid_0's auc: 0.812164\n",
      "[420]\tvalid_0's auc: 0.812163\n",
      "[421]\tvalid_0's auc: 0.8122\n",
      "[422]\tvalid_0's auc: 0.812199\n",
      "[423]\tvalid_0's auc: 0.812206\n",
      "[424]\tvalid_0's auc: 0.812231\n",
      "[425]\tvalid_0's auc: 0.812228\n",
      "[426]\tvalid_0's auc: 0.812234\n",
      "[427]\tvalid_0's auc: 0.812247\n",
      "[428]\tvalid_0's auc: 0.812274\n",
      "[429]\tvalid_0's auc: 0.81228\n",
      "[430]\tvalid_0's auc: 0.812288\n",
      "[431]\tvalid_0's auc: 0.812287\n",
      "[432]\tvalid_0's auc: 0.812284\n",
      "[433]\tvalid_0's auc: 0.812291\n",
      "[434]\tvalid_0's auc: 0.81231\n",
      "[435]\tvalid_0's auc: 0.81231\n",
      "[436]\tvalid_0's auc: 0.812295\n",
      "[437]\tvalid_0's auc: 0.812315\n",
      "[438]\tvalid_0's auc: 0.812316\n",
      "[439]\tvalid_0's auc: 0.812345\n",
      "[440]\tvalid_0's auc: 0.812373\n",
      "[441]\tvalid_0's auc: 0.8124\n",
      "[442]\tvalid_0's auc: 0.812403\n",
      "[443]\tvalid_0's auc: 0.812416\n",
      "[444]\tvalid_0's auc: 0.812426\n",
      "[445]\tvalid_0's auc: 0.812424\n",
      "[446]\tvalid_0's auc: 0.812425\n",
      "[447]\tvalid_0's auc: 0.812427\n",
      "[448]\tvalid_0's auc: 0.812429\n",
      "[449]\tvalid_0's auc: 0.812454\n",
      "[450]\tvalid_0's auc: 0.812472\n",
      "[451]\tvalid_0's auc: 0.812492\n",
      "[452]\tvalid_0's auc: 0.812491\n",
      "[453]\tvalid_0's auc: 0.812501\n",
      "[454]\tvalid_0's auc: 0.812499\n",
      "[455]\tvalid_0's auc: 0.812513\n",
      "[456]\tvalid_0's auc: 0.812528\n",
      "[457]\tvalid_0's auc: 0.812524\n",
      "[458]\tvalid_0's auc: 0.812554\n",
      "[459]\tvalid_0's auc: 0.812552\n",
      "[460]\tvalid_0's auc: 0.812565\n",
      "[461]\tvalid_0's auc: 0.81257\n",
      "[462]\tvalid_0's auc: 0.81257\n",
      "[463]\tvalid_0's auc: 0.812614\n",
      "[464]\tvalid_0's auc: 0.812615\n",
      "[465]\tvalid_0's auc: 0.812642\n",
      "[466]\tvalid_0's auc: 0.812654\n",
      "[467]\tvalid_0's auc: 0.812655\n",
      "[468]\tvalid_0's auc: 0.812694\n",
      "[469]\tvalid_0's auc: 0.812701\n",
      "[470]\tvalid_0's auc: 0.812694\n",
      "[471]\tvalid_0's auc: 0.812716\n",
      "[472]\tvalid_0's auc: 0.812716\n",
      "[473]\tvalid_0's auc: 0.812718\n",
      "[474]\tvalid_0's auc: 0.812735\n",
      "[475]\tvalid_0's auc: 0.812742\n",
      "[476]\tvalid_0's auc: 0.812745\n",
      "[477]\tvalid_0's auc: 0.81276\n",
      "[478]\tvalid_0's auc: 0.81277\n",
      "[479]\tvalid_0's auc: 0.812788\n",
      "[480]\tvalid_0's auc: 0.812798\n",
      "[481]\tvalid_0's auc: 0.8128\n",
      "[482]\tvalid_0's auc: 0.812801\n",
      "[483]\tvalid_0's auc: 0.812816\n",
      "[484]\tvalid_0's auc: 0.812812\n",
      "[485]\tvalid_0's auc: 0.812813\n",
      "[486]\tvalid_0's auc: 0.812848\n",
      "[487]\tvalid_0's auc: 0.812869\n",
      "[488]\tvalid_0's auc: 0.812853\n",
      "[489]\tvalid_0's auc: 0.812873\n",
      "[490]\tvalid_0's auc: 0.812893\n",
      "[491]\tvalid_0's auc: 0.81291\n",
      "[492]\tvalid_0's auc: 0.812916\n",
      "[493]\tvalid_0's auc: 0.812933\n",
      "[494]\tvalid_0's auc: 0.812944\n",
      "[495]\tvalid_0's auc: 0.812943\n",
      "[496]\tvalid_0's auc: 0.812934\n",
      "[497]\tvalid_0's auc: 0.812951\n",
      "[498]\tvalid_0's auc: 0.812956\n",
      "[499]\tvalid_0's auc: 0.812957\n",
      "[500]\tvalid_0's auc: 0.812958\n",
      "[501]\tvalid_0's auc: 0.812982\n",
      "[502]\tvalid_0's auc: 0.812984\n",
      "[503]\tvalid_0's auc: 0.81299\n",
      "[504]\tvalid_0's auc: 0.812984\n",
      "[505]\tvalid_0's auc: 0.812995\n",
      "[506]\tvalid_0's auc: 0.812996\n",
      "[507]\tvalid_0's auc: 0.812995\n",
      "[508]\tvalid_0's auc: 0.813005\n",
      "[509]\tvalid_0's auc: 0.813015\n",
      "[510]\tvalid_0's auc: 0.813011\n",
      "[511]\tvalid_0's auc: 0.813028\n",
      "[512]\tvalid_0's auc: 0.813023\n",
      "[513]\tvalid_0's auc: 0.813021\n",
      "[514]\tvalid_0's auc: 0.81303\n",
      "[515]\tvalid_0's auc: 0.813036\n",
      "[516]\tvalid_0's auc: 0.81305\n",
      "[517]\tvalid_0's auc: 0.813058\n",
      "[518]\tvalid_0's auc: 0.813053\n",
      "[519]\tvalid_0's auc: 0.813077\n",
      "[520]\tvalid_0's auc: 0.813081\n",
      "[521]\tvalid_0's auc: 0.8131\n",
      "[522]\tvalid_0's auc: 0.813096\n",
      "[523]\tvalid_0's auc: 0.813112\n",
      "[524]\tvalid_0's auc: 0.813141\n",
      "[525]\tvalid_0's auc: 0.81314\n",
      "[526]\tvalid_0's auc: 0.813136\n",
      "[527]\tvalid_0's auc: 0.813151\n",
      "[528]\tvalid_0's auc: 0.813137\n",
      "[529]\tvalid_0's auc: 0.813148\n",
      "[530]\tvalid_0's auc: 0.813156\n",
      "[531]\tvalid_0's auc: 0.813156\n",
      "[532]\tvalid_0's auc: 0.813146\n",
      "[533]\tvalid_0's auc: 0.813141\n",
      "[534]\tvalid_0's auc: 0.813146\n",
      "[535]\tvalid_0's auc: 0.813184\n",
      "[536]\tvalid_0's auc: 0.813217\n",
      "[537]\tvalid_0's auc: 0.813209\n",
      "[538]\tvalid_0's auc: 0.813213\n",
      "[539]\tvalid_0's auc: 0.813216\n",
      "[540]\tvalid_0's auc: 0.81324\n",
      "[541]\tvalid_0's auc: 0.813268\n",
      "[542]\tvalid_0's auc: 0.813271\n",
      "[543]\tvalid_0's auc: 0.813285\n",
      "[544]\tvalid_0's auc: 0.81329\n",
      "[545]\tvalid_0's auc: 0.813339\n",
      "[546]\tvalid_0's auc: 0.813345\n",
      "[547]\tvalid_0's auc: 0.813354\n",
      "[548]\tvalid_0's auc: 0.813361\n",
      "[549]\tvalid_0's auc: 0.813362\n",
      "[550]\tvalid_0's auc: 0.813362\n",
      "[551]\tvalid_0's auc: 0.81336\n",
      "[552]\tvalid_0's auc: 0.81337\n",
      "[553]\tvalid_0's auc: 0.813372\n",
      "[554]\tvalid_0's auc: 0.813381\n",
      "[555]\tvalid_0's auc: 0.813384\n",
      "[556]\tvalid_0's auc: 0.813388\n",
      "[557]\tvalid_0's auc: 0.813392\n",
      "[558]\tvalid_0's auc: 0.813383\n",
      "[559]\tvalid_0's auc: 0.813378\n",
      "[560]\tvalid_0's auc: 0.813377\n",
      "[561]\tvalid_0's auc: 0.813372\n",
      "[562]\tvalid_0's auc: 0.813385\n",
      "[563]\tvalid_0's auc: 0.813377\n",
      "[564]\tvalid_0's auc: 0.813378\n",
      "[565]\tvalid_0's auc: 0.813385\n",
      "[566]\tvalid_0's auc: 0.813384\n",
      "[567]\tvalid_0's auc: 0.813387\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's auc: 0.813392\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "bst = lgb.train(params, d_train, num_boost_round, valid_sets=d_valid, \n",
    "                categorical_feature=cat_cols,\n",
    "                verbose_eval=1,\n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('end_sep_prob', 241),\n",
       " ('cls', 238),\n",
       " ('end_prob', 236),\n",
       " ('next_cls', 220),\n",
       " ('start_prob', 181),\n",
       " ('para_len_ratio', 162),\n",
       " ('num_words', 154),\n",
       " ('start_sep_prob', 131),\n",
       " ('para_len', 120),\n",
       " ('end_ratio', 119),\n",
       " ('pre_cls', 116),\n",
       " ('model_matches', 104),\n",
       " ('start_ratio', 99),\n",
       " ('mean_prob', 98),\n",
       " ('start_cls', 95),\n",
       " ('end_cls', 89),\n",
       " ('start', 77),\n",
       " ('class_ratio', 75),\n",
       " ('end', 72),\n",
       " ('model14', 23),\n",
       " ('start_eq2', 21),\n",
       " ('end_eq2', 20),\n",
       " ('model1', 16),\n",
       " ('max_prob', 13),\n",
       " ('model3', 12),\n",
       " ('model12', 11),\n",
       " ('model8', 8),\n",
       " ('model11', 8),\n",
       " ('end_eq', 5),\n",
       " ('model2', 5),\n",
       " ('model0', 4),\n",
       " ('model5', 3),\n",
       " ('model10', 3),\n",
       " ('model7', 2),\n",
       " ('start_eq', 1),\n",
       " ('model4', 1),\n",
       " ('model6', 1),\n",
       " ('model9', 1),\n",
       " ('num_classes', 0),\n",
       " ('model13', 0),\n",
       " ('model15', 0),\n",
       " ('model16', 0)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(zip(bst.feature_name(), bst.feature_importance()))\n",
    "l.sort(key=lambda x: -x[1])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decodes(df, cols, para_classifier):\n",
    "  df['pred'] = para_classifier.predict(df[cols])\n",
    "  ids = set(df.id)\n",
    "  ids_list, types_list, preds_list = [], [], []\n",
    "  for id in tqdm(ids):\n",
    "    d = df[df.id == id]\n",
    "  #   max_idx, max_score = 0, -1\n",
    "  #   for i in range(len(votes)):\n",
    "  #     d_ = d[d[f'model{i}'] > 0]\n",
    "  #     if len(d_):\n",
    "  #       score = d_.pred.mean()\n",
    "  #       if score > max_score:\n",
    "  #         max_score = score\n",
    "  #         max_idx = i\n",
    "  #   d = d[d[f'model{max_idx}'] > 0]\n",
    "    if len(d):\n",
    "      d = d.sort_values(['pred'], ascending=[False])\n",
    "      num_words = d.num_words.values[0]\n",
    "      used = np.zeros(num_words)\n",
    "      for row in d.itertuples():\n",
    "        # if row.model0 < 1 and row.pred < 0.9:\n",
    "        # #   continue\n",
    "        # if row.model0 < 1 and not row.cls in [2]:\n",
    "        #   continue\n",
    "        start, end = row.start, row.end\n",
    "        # cls = row.cls\n",
    "        cls = row.cls\n",
    "        # if not cls:\n",
    "        #   continue\n",
    "        # if used[start: end].sum() == 0:\n",
    "        # if row.model0 < 1 or row.pred < 0.9:\n",
    "        #   continue\n",
    "        if used[start: end].sum() / (end - start) < 0.01:\n",
    "          if row.mean_prob > proba_thresh[id2dis[cls]]:\n",
    "            used[start: end] = 1\n",
    "            if cls:\n",
    "              ids_list.append(id)\n",
    "              types_list.append(id2dis[cls])\n",
    "              preds_list.append(' '.join([str(x) for x in range(start, end)]))\n",
    "        if used.sum() == num_words:\n",
    "          break\n",
    "  df = pd.DataFrame({\n",
    "    'id': ids_list,\n",
    "    'class': types_list,\n",
    "    'predictionstring': preds_list,\n",
    "  })\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a841e6ea9f4030bf87e755c7963fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred = greedy_decodes(dvalid, cols, bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = dvalid[['id', 'start', 'end', 'cls', 'start_prob', 'end_prob', 'model0', 'score', 'match', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = list(set(dv.id))[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>cls</th>\n",
       "      <th>start_prob</th>\n",
       "      <th>end_prob</th>\n",
       "      <th>model0</th>\n",
       "      <th>score</th>\n",
       "      <th>match</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350852</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350853</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350854</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350855</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350856</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>26</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350857</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350858</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350859</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350860</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350861</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350862</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350863</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>133</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350864</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>147</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350865</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>147</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350866</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>147</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350867</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>177</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350868</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>177</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350869</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>178</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350870</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>183</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350871</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>199</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350872</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>211</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350873</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>225</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350874</th>\n",
       "      <td>B659CCF9A5C5</td>\n",
       "      <td>280</td>\n",
       "      <td>307</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  start  end  cls  start_prob  end_prob  model0  score  \\\n",
       "350852  B659CCF9A5C5      0    8    3        0.99      0.99       1   0.57   \n",
       "350853  B659CCF9A5C5      8   17    1        0.41      0.97       0   0.33   \n",
       "350854  B659CCF9A5C5      9   17    1        0.95      0.97       1   0.38   \n",
       "350855  B659CCF9A5C5     18   26    1        0.97      0.98       1   0.89   \n",
       "350856  B659CCF9A5C5     26   48    1        0.94      0.93       1   1.00   \n",
       "350857  B659CCF9A5C5     48  133    2        0.90      0.96       1   1.00   \n",
       "350858  B659CCF9A5C5    133  147    1        0.64      0.63       0   0.32   \n",
       "350859  B659CCF9A5C5    133  177    2        0.34      0.94       0   0.00   \n",
       "350860  B659CCF9A5C5    133  178    2        0.34      0.66       0   0.01   \n",
       "350861  B659CCF9A5C5    133  183    2        0.34      0.65       0   0.08   \n",
       "350862  B659CCF9A5C5    133  196    2        0.34      0.65       0   0.24   \n",
       "350863  B659CCF9A5C5    133  211    2        0.34      0.71       1   0.44   \n",
       "350864  B659CCF9A5C5    147  177    2        0.86      0.94       0   0.00   \n",
       "350865  B659CCF9A5C5    147  178    2        0.86      0.66       0   0.02   \n",
       "350866  B659CCF9A5C5    147  211    2        0.86      0.71       0   0.53   \n",
       "350867  B659CCF9A5C5    177  199    2        0.66      0.65       0   0.65   \n",
       "350868  B659CCF9A5C5    177  211    2        0.66      0.71       0   1.00   \n",
       "350869  B659CCF9A5C5    178  199    2        0.66      0.65       0   0.62   \n",
       "350870  B659CCF9A5C5    183  199    2        0.66      0.65       0   0.47   \n",
       "350871  B659CCF9A5C5    199  211    2        0.68      0.71       0   0.35   \n",
       "350872  B659CCF9A5C5    211  225    1        0.86      0.89       1   0.00   \n",
       "350873  B659CCF9A5C5    225  280    2        0.93      0.98       1   0.29   \n",
       "350874  B659CCF9A5C5    280  307    4        0.99      0.99       1   1.00   \n",
       "\n",
       "        match  pred  \n",
       "350852      1  0.28  \n",
       "350853      0  0.34  \n",
       "350854      0  0.21  \n",
       "350855      1  0.85  \n",
       "350856      1  0.85  \n",
       "350857      1  0.79  \n",
       "350858      0  0.42  \n",
       "350859      0  0.50  \n",
       "350860      0  0.45  \n",
       "350861      0  0.45  \n",
       "350862      0  0.47  \n",
       "350863      0  0.62  \n",
       "350864      0  0.33  \n",
       "350865      0  0.35  \n",
       "350866      1  0.61  \n",
       "350867      1  0.18  \n",
       "350868      1  0.30  \n",
       "350869      1  0.17  \n",
       "350870      0  0.14  \n",
       "350871      0  0.19  \n",
       "350872      0  0.71  \n",
       "350873      0  0.89  \n",
       "350874      1  0.96  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv[dv.id==id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38DD98A04439</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>156 157 158 159 160 161 162 163 164 165 166 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38DD98A04439</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>184 185 186 187 188 189 190 191 192 193 194 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38DD98A04439</td>\n",
       "      <td>Claim</td>\n",
       "      <td>49 50 51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38DD98A04439</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38DD98A04439</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>113 114 115 116 117 118 119 120 121 122 123 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27893</th>\n",
       "      <td>1B065440759E</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>197 198 199 200 201 202 203 204 205 206 207 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27894</th>\n",
       "      <td>1B065440759E</td>\n",
       "      <td>Claim</td>\n",
       "      <td>311 312 313 314 315 316 317 318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27895</th>\n",
       "      <td>1B065440759E</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>319 320 321 322 323 324 325 326 327 328 329 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27896</th>\n",
       "      <td>1B065440759E</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>120 121 122 123 124 125 126 127 128 129 130 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27897</th>\n",
       "      <td>1B065440759E</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>296 297 298 299 300 301 302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27898 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                 class  \\\n",
       "0      38DD98A04439              Evidence   \n",
       "1      38DD98A04439  Concluding Statement   \n",
       "2      38DD98A04439                 Claim   \n",
       "3      38DD98A04439              Evidence   \n",
       "4      38DD98A04439              Evidence   \n",
       "...             ...                   ...   \n",
       "27893  1B065440759E              Evidence   \n",
       "27894  1B065440759E                 Claim   \n",
       "27895  1B065440759E              Evidence   \n",
       "27896  1B065440759E              Evidence   \n",
       "27897  1B065440759E              Evidence   \n",
       "\n",
       "                                        predictionstring  \n",
       "0      156 157 158 159 160 161 162 163 164 165 166 16...  \n",
       "1      184 185 186 187 188 189 190 191 192 193 194 19...  \n",
       "2                                               49 50 51  \n",
       "3      62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 7...  \n",
       "4      113 114 115 116 117 118 119 120 121 122 123 12...  \n",
       "...                                                  ...  \n",
       "27893  197 198 199 200 201 202 203 204 205 206 207 20...  \n",
       "27894                    311 312 313 314 315 316 317 318  \n",
       "27895  319 320 321 322 323 324 325 326 327 328 329 33...  \n",
       "27896  120 121 122 123 124 125 126 127 128 129 130 13...  \n",
       "27897                        296 297 298 299 300 301 302  \n",
       "\n",
       "[27898 rows x 3 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ea015da250478d9e76e090540b6683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calc_f1:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 3430601751.py:2 in <module>- res['f1/Overall']: 0.7103608015083883\n",
      "ic| 3430601751.py:3 in <module>\n",
      "    res: {'acc/Claim': 0.7114007906827653,\n",
      "          'acc/Concluding Statement': 0.8434720739950196,\n",
      "          'acc/Counterclaim': 0.6193672099712368,\n",
      "          'acc/Evidence': 0.7592859518793658,\n",
      "          'acc/Lead': 0.8286020353508302,\n",
      "          'acc/Position': 0.7348157982077663,\n",
      "          'acc/Rebuttal': 0.5327455919395466,\n",
      "          'f1/Claim': 0.6845920518225284,\n",
      "          'f1/Concluding Statement': 0.865012769062386,\n",
      "          'f1/Counterclaim': 0.5902238465052535,\n",
      "          'f1/Evidence': 0.7561002539472231,\n",
      "          'f1/Lead': 0.8375744450460205,\n",
      "          'f1/Overall': 0.7103608015083883,\n",
      "          'f1/Position': 0.7287689269256089,\n",
      "          'f1/Rebuttal': 0.5102533172496985,\n",
      "          'recall/Claim': 0.6597304795877923,\n",
      "          'recall/Concluding Statement': 0.8876825159116436,\n",
      "          'recall/Counterclaim': 0.5636998254799301,\n",
      "          'recall/Evidence': 0.7529411764705882,\n",
      "          'recall/Lead': 0.8467432950191571,\n",
      "          'recall/Position': 0.722820763956905,\n",
      "          'recall/Rebuttal': 0.4895833333333333}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1/Overall': 0.7103608015083883,\n",
       " 'f1/Claim': 0.6845920518225284,\n",
       " 'acc/Claim': 0.7114007906827653,\n",
       " 'recall/Claim': 0.6597304795877923,\n",
       " 'f1/Evidence': 0.7561002539472231,\n",
       " 'acc/Evidence': 0.7592859518793658,\n",
       " 'recall/Evidence': 0.7529411764705882,\n",
       " 'f1/Position': 0.7287689269256089,\n",
       " 'acc/Position': 0.7348157982077663,\n",
       " 'recall/Position': 0.722820763956905,\n",
       " 'f1/Concluding Statement': 0.865012769062386,\n",
       " 'acc/Concluding Statement': 0.8434720739950196,\n",
       " 'recall/Concluding Statement': 0.8876825159116436,\n",
       " 'f1/Lead': 0.8375744450460205,\n",
       " 'acc/Lead': 0.8286020353508302,\n",
       " 'recall/Lead': 0.8467432950191571,\n",
       " 'f1/Counterclaim': 0.5902238465052535,\n",
       " 'acc/Counterclaim': 0.6193672099712368,\n",
       " 'recall/Counterclaim': 0.5636998254799301,\n",
       " 'f1/Rebuttal': 0.5102533172496985,\n",
       " 'acc/Rebuttal': 0.5327455919395466,\n",
       " 'recall/Rebuttal': 0.4895833333333333}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = calc_metrics(df_gt[df_gt.id.isin(set(dvalid.id))], df_pred)\n",
    "ic(res['f1/Overall'])\n",
    "ic(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e1511501be64c09e2f1eb58c3220ebc9ce84b491d308a480caed250bbb4af51"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
